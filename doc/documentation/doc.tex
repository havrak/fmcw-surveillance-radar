\def\PageLayout{single-no-print}
\def\DocLanguage{en}
\def\PackagesIncludeTikz{yes}
\def\PackagesIncludeBib{yes}

\input{metadata}
\input{../templates/dimensions_paper}
\input{../templates/packages}
\input{../templates/macros}
\input{../templates/xmp}
\input{../templates/doc_paper}

\addbibresource{bibliography.bib}
\usepackage{pdfpages}

\newcommand{\sidar}{SiRad Easy\textsuperscript{\copyright} }
\newcommand{\boldred}[1]{\textbf{\textcolor{red}{#1}}}
\newcommand{\boldblue}[1]{\textbf{\textcolor{blue}{#1}}}
% \newcommand{\red}[1]{\textcolor{red}{#1}}


\begin{document}

\include{title_page}

\tableofcontents

\newpage
\pagenumbering{arabic}
\setcounter{page}{1}

\include{abbreviations}

\include{introduction}

\pagestyle{fancy}

\chapter{FMCW Radar Fundamentals}

While classical Continuous Wave (CW) radars broadcast signal only on a single frequency FMCW radars make a linear sweep across given bandwidth.
This approach enables range estimation without requiring pulsed transmissions while still allowing speed measurements using the Doppler shift.
However, velocity calculations in FMCW radars are more complex compared to single-frequency CW radars.

The "MW" suffix in FMCW radar denotes that the system operates in the microwave frequency range.
These high frequencies enable use of compact antenna arrays, that sometimes can even be integrated directly on-chip.
Additionally, the millimeter-wave (MMW) portion of the spectrum is typically license-free \cite{spektrumCTU} and offers large bandwidths, reducing the risk of interference.

\section{Comparison FMCW Radar to Pulse Radar}

Distance measurement using radar predates FMCW technology by several decades.
Early radar systems primarily relied on pulsed signals, where distance can be calculated from the time of flight $t$ of the signal as
\begin{equation}
  d = \frac{c_o \cdot t}{2}.
  \label{eq:distance}
\end{equation}
Speed calculation is also relatively as Doppler effect is much clearer
\begin{equation}
  v = \frac{f_\mathrm{dop} c_o}{2f_\mathrm{rad}},
  \label{eq:dopler}
\end{equation}
where $f_\mathrm{dop}$ is Doppler frequency, $c_o$ is speed of light and $f_\mathrm{rad}$ is frequency of the radar signal \cite{jankiraman2018}.

While this approach is conceptually straightforward, it has several limitations, particularly in applications requiring high precision at close range.
Achieving fine resolution in distance measurement necessitates very short pulses.
However, to maintain sufficient signal-to-noise ratio (SNR), the transmitted pulse power must remain high, regardless of the number of pulses \cite{jankiraman2018}.

Maintaining high average transmission power poses legal and technical challenges.
It increases the risk of interference with other devices and demands bulky, high-power circuitry -- often requiring high voltages and even vacuum tubes.
Consequently, pulsed radar is predominantly used in applications where fine range resolution is not essential, such as long-range target detection.

One key advantage of pulsed radar is its relatively simple data processing.
In contrast, FMCW radar data processing is more complex due to the interdependence of distance and velocity measurements -- both distance and velocity of a target contribute to frequency changes in the received signal.

\section{Basic principles of ideal FMCW radar}

Let us picture an ideal FMCW radar system sending a periodic chirp with periodically repeated frequency frequency sweep from $f_\mathrm{c}$ to $f_\mathrm{c}+BW$.
Placed in in scene with single larger target that reflect all incoming signal.
Aside form sawtooth waveform other modulations are also frequently used such as linear triangular modulation or segmented linear frequency modulation.
These offer some advantages but the nature of the beat signal (which forms a sine wave with sawtooth modulation) is more complex.
Especially in case of triangle modulations when multiple targets are present \cite{jankiraman2018}.
\sidar kit, used in this thesis, technically uses a segmented linear frequency modulation due to its limited computational power \cite{sidarPRO} but the mathematical principles are similar as for sawtooth.

\begin{figure}[h!]
  \centering
  \begin{tikzpicture}[>=latex, scale=1]

    % Axes
    \draw[->] (0, 0) -- (8, 0) node[below] {$t$};
    \draw[->] (0, 0) -- (0, 5) node[left] {$f$};

    % Horizontal lines for BW
    \draw[dashed] (0, 4.5) -- (7.5, 4.5);
    \draw[dashed] (0, 1) -- (7.5, 1);
    \draw[dashed] (2.5, -0.05) -- (2.5, 4.7);

    % Labels for fc and BW
    \node[left] at (0, 1) {$f_c$};
    \draw[<->] (-0.5, 1) -- (-0.5, 4.5) node[midway,left] {$BW$};

    % Triangular wave for Tx
    \draw[thick,blue] (0, 1) -- (2.5, 4.5);
    \draw[thick,blue]	(2.5, 1) -- (5, 4.5);
    \draw[thick, dashed, blue] (5, 1) -- (6, 2.4);

    % Triangular wave for Rx (offset version)
    \draw[thick,red] (0.5, 1) -- (3, 4.5);
    \draw[thick,red] (3, 1) -- (5.5, 4.5);
    \draw[thick, dashed, red] (5.4, 1) -- (6.4, 2.4);

    % Label for Tch
    \draw[-] (2.5, -0.05) -- (2.5, 0.05) node[below] {$T_{\text{ch}}$};

    % Labels for Tx and Rx
    \node[blue] at (4.2, 4.1) {\small Tx};
    \node[red] at (5.3, 3.7) {\small Rx};

    % Sweep slope and fb
    \draw[<->] (1, 1) arc[start angle=0, end angle=55, radius=1];
    \node at (1.5, 1.3) {\small $k_{\text{sw}}$};
    \draw[<->] (1.5, 2.37) -- (1.5, 3.12) node[above, left] {$f_b$};

    % Small time delay (tau)
    \draw[<->] (2.5, 0.7) -- (3, 0.7) node[midway,below] {$\tau$};

  \end{tikzpicture}

	\caption[Ideal relation of frequency on time for received and sent signal \cite{adler2023}]{Ideal relation of frequency on time for received and sent signal \cite{adler2023}}
  \label{fig:fmcw_ideal}
\end{figure}

We can clearly see that in given time $t$ the frequency spread from sent signal to received signal is proportional to the time delay $\tau$.
However doing some simple subtraction in spectrogram of both signals isn't really feasible -- the calculation need to take a smarter approach.


Let us define the chirp slope $k_\mathrm{sw}$ with which we can describe the change in frequency of the broadcasted signal as
\begin{equation}
  \Delta f_\mathrm{s}(t) = k_\mathrm{sw}t = \frac{BW}{T_\mathrm{ch}} t,
  \label{eq:deltaf}
\end{equation}
where $t$ is the time goes from 0 to chirp length $T_\mathrm{ch}$.
Standard equation of FM signal can be written as
\begin{equation}
  s_\mathrm{t}(t) = A \cos\left(\omega_c t + 2\pi \int_{0}^{t} f_\mathrm{s}(t) \mathrm{d}t\right),
  \label{eq:fm}
\end{equation}
where $A$ is amplitude of the signal, $\omega_c$ is carrier frequency and $f(s)$ is frequency of the signal.
Substituting (\ref{eq:deltaf}) into (\ref{eq:fm}) we get the signal broadcasted by the radar \cite{suleymanov2016}
\begin{equation}
  s_\mathrm{t}(t) = A \cos(\omega_c t + \pi k_\mathrm{sw}t^2).
  \label{eq:fm2}
\end{equation}

Signal bounced back from the target will have the same equation with the only difference being the time delay $\tau$,
\begin{equation}
  s_\mathrm{r}(t) = A \cos(\omega_c (t - \tau) + \pi k_\mathrm{sw}(t - \tau)^2).
  \label{eq:fm3}
\end{equation}
Now we can calculate the product of the two signals, this can be done easily in the real world using a frequency mixer.
The result of the multiplication is  \cite{suleymanov2016}
\begin{align}
  s(t) = s_\mathrm{r}(t) \cdot  s_\mathrm{t}(t) & = \frac{A^2}{2}\cos\left(2(\omega_c - 2\pi k_\mathrm{sw}T_\tau)t + 2\pi k_{sw}t^2 + (\pi k_\mathrm{sw} \tau^2 - \omega_c \tau) \right)+ \nonumber \\
                                                & +\frac{A^2}{2} \cos\left(2\pi k_\mathrm{sw} \tau t + (\omega_c \tau - \pi k_\mathrm{sw} \tau^2)\right).
  \label{eq:fm4}
\end{align}
First additive term will lead to a signal with very high frequency, well above $2\omega_c$, this term doesn't carry any useful information and is usually filtered out -- either by low pass filter or the frequency mixer itself.
Second term is so call beat signal whose frequency is directly proportional to the time delay $\tau$.
Deriving the second argument by time we get the frequency of the beat signal \cite{graham2005}
\begin{equation}
  f_\mathrm{b} = \frac{1}{2\pi}\frac{\partial}{\partial t} \left(2\pi k_\mathrm{sw} \tau t + (\omega_c \tau - \pi k_\mathrm{sw} \tau^2)\right) = k_\mathrm{sw} \tau.
  \label{eq:fb}
\end{equation}

Calculating the distance to the target is now trivial, delay $\tau$ is equal to the time it takes for the signal to travel to the target and back \cite{graham2005}
\begin{equation}
  R = \frac{c_0 \tau}{2},
  \label{eq:distance2}
\end{equation}
By substituting (\ref{eq:fb}) into (\ref{eq:distance2}) we get the equation for distance \cite{graham2005}
\begin{equation}
  R = \frac{c_0 f_\mathrm{b}}{2k_\mathrm{sw}}= \frac{c_o f_\mathrm{b} T_{\mathrm{ch}}}{2 BW}.
  \label{eq:distance3}
\end{equation}


\subsection{Limits of Range Measurement}

Maximal distance is given by the time it takes for the signal to travel from the radar to the target and back.
Would the distance be greater than a time of single chirp the signal would be interpreted as coming from a closer target.
That gives us an maximal limit on beat frequency $f_\mathrm{b} = BW$.

However in most case the limit will imposed not by $T_\mathrm{ch}$ respectively $BW$ but by sampling frequency $f_\mathrm{s}$.
In order to avoid aliasing the Nyquist-Shannon theorem must be satisfied thus limiting the maximal beat frequency to $f_\mathrm{s}/2$ and resulting in maximal distance of \cite{jankiraman2018}
\begin{equation}
  R = \frac{c_o f_\mathrm{s}}{4k_\mathrm{sw}}.
  \label{eq:distance4max}
\end{equation}

While sampling with frequency $f_\mathrm{s}$ we get $N =\mathrm{f}_\mathrm{s} T_\mathrm{ch}$ samples applying a DFT to the signal we get $N$ samples in spectrum with frequency resolution of
\begin{equation}
  \Delta f_\mathrm{b} = \frac{f_\mathrm{s}}{N} = \frac{1}{T_{ch}}.
  \label{eq:resolution}
\end{equation}
We can see that the resolution of spectrum is only inversely proportional to the chirp length and doesn't have any relation to sampling frequency \cite{jankiraman2018}.
Now we can enter $\Delta f_\mathrm{b}$ into (\ref{eq:distance3}) to get the minimal distance that can be measured as
\begin{equation}
  \Delta R = \frac{c_o}{2BW}
  \label{eq:distance5min}
\end{equation}
Thus in order to increase resolution in range a wider bandwidth is needed.

There are of course other effect impeding the resolution of the radar system -- such a phase noise around targets or sweep nonlinearity.
Sweep nonlinearity can be either in the ramp itself -- leading to decreasing resolution with range (with both linear and quadratic errors present) \cite{graham2005}.
Or in sweep recovery (time to return to the start of the sweep) which leads to a constant decrease in resolution \cite{piper1995}.
Both are however largely compensated in modern radar systems by using a closed feedback loop \cite{graham2005}.


\subsection{Speed Measurement}

In order to demonstrate the effect of moving target on the beat frequency we can redefine the time delay $\tau$ as
\begin{equation}
  \tau = \frac{2(R_0+vt)}{c_o}
  \label{eq:tau222}
\end{equation}
where $R_0$ is the initial distance to the target and $v$ is the radial speed of the target.
Within a single chirp there is no way to distinguish between the effects distance and speed of the target -- thus multiple chirps are needed \cite{suleymanov2016}.
We can rewrite the equation (\ref{eq:tau222}) as
\begin{equation}
  \tau = \frac{2(R_0 v(nT_\mathrm{ch} + t_\mathrm{s}))}{c_0}
  \label{eq:tau2}
\end{equation}
where $n$ is the number of chirps, $T_\mathrm{ch}$ is the chirp length (or in case of segmented signal whole cycle duration) and $t_\mathrm{s}$ denotes time within a single chirp ($0 \leq t_\mathrm{s} \leq T_\mathrm{ch}$).
Substituting (\ref{eq:tau2}) into low frequency part (\ref{eq:fm4}) leads to very complex equation, however according to \cite{suleymanov2016} most of the terms can be neglected leading us to
\begin{equation}
  s(t_\mathrm{s}, n) = \frac{A^2}{2} \cos\left(\frac{4\pi k_\mathrm{sw} R_0}{c_0} t_\mathrm{s} + \frac{2\omega_c v n}{c_0} T_\mathrm{ch} + \varphi_0 \right),
  \label{eq:fb2}
\end{equation}
where $\varphi_0$ is a phase shift given by the initial distance to the target.
Its clear that first element describes predominantly the distance to the target and the second one the speed of the target.
We can also see that speed will not affect a beat frequency in a single spectrum but will lead to a phase shift across multiple spectrums \cite{suleymanov2016}.

In order to calculate Doppler shift frequency
\begin{equation}
  f_\mathrm{d} = \frac{2f_\mathrm{c}v}{c_0},
  \label{eq:Doppler2}
\end{equation}
where $f_c$ is the center frequency, 2D Fourier transform can be used.
At first FFT is run on each individual chirps and then another FFT is applied to these individual outputs in order ot determine phase shift.
Given that FFT spectrum is calculated from complex data both halves of the spectrum contain useful information -- after applying \verb|fftshift| we get spectrum from negative radial speeds (moving away from the radar) to positive (moving towards the radar) with zero in the middle.
This will lead to a so called range-Doppler map which on one axis contains information about speed and on second distance of the target.

Speed resolution is derived from a number of chirps $N$ we are analyzing and their length $T_{\mathrm{ch}}$ as \cite{suleymanov2016}
\begin{equation}
  \Delta v = \frac{c_0}{2f_c} \frac{1}{NT_{\mathrm{ch}}}.
  \label{eq:Doppler3}
\end{equation}
Maximal speed is dictated by how large of a phase shift can we measure without ambiguity -- that is $\pm \pi$.
From (\ref{eq:fb2}) we can formulate the maximal speed measurable as
\[
  v_\mathrm{max} = \frac{c_0}{4f_c T_\mathrm{ch}},
\]
according to \cite{fmcwSpeed}.
But given the nature of FFT this speed applies to negative side of the spectrum - that is for targets moving away from the radar.
In case target is moving towards the radar the speed limit is smaller by a single speed bin width.

\section{Radar equation}

Fundamental to all radar systems is so called radar equation.
This formula takes establishes a relation of transmitted/received power, RCS of the target and other system parameters to maximal range of the radar.
It can be written as
\begin{equation}
	R_\mathrm{max}^4 = \left(\frac{P_{\mathrm{CW}}G_\mathrm{T}G_\mathrm{R}\lambda^2}{(4\pi)^3 L k T F_\mathrm{R}B_\mathrm{Ro}(SNR_\mathrm{Ro})} \sigma_T\right),
	\label{eq:radar_eq}
\end{equation}
where $P_\mathrm{CW}$ is average system power in watts, $G_\mathrm{T}$ and $G_\mathrm{R}$ gain of transmitting and receiving antennas, $\sigma_T$ is radar cross section of the target, $\lambda$ is wavelength, $L$ is system loss, $k$ is Boltzmann's constant, $T$ is effective temperature of the system in Kelvin, $F_\mathrm{R}$ is receiver noise figure, $B_\mathrm{Ro}$ is receiver bandwidth and $SNR_\mathrm{Ro}$ is required signal to noise ratio \cite{jankiraman2018}.


Knowing all parameters, or calibrating the system based on know reference, we can  calculate target's RCS.
This value gives us much clear understating of the target as opposed to just displaying power received or its logarithm.
This is due to RCS being a constant value for a given target and its orientation, regardless of the distance \cite{richards2022}.

\section{Angle of Arrival/Spatial Information}

Commonly in order to get spatial information radars rely on multiple RX antennas.
This allows for estimation of the angle of arrival (AoA) of the target by taking into analyzing phase differences between the signals received by different antennas \cite{suleymanov2016}.
However usually only single linear series of RX antennas is employed, therefore only one angle can be estimated.

More complex MIMO systems employ not only multiple RX antennas but also multiple TX antennas.
Multiple TX antennas enable beamforming, which is the process of steering the radar beam in a specific direction using positive interference.
If antennas are still arranged in a linear array this only makes angle of estimation more accurate by effectively creating virtual RX antennas.
However if 2D arrangement of antennas is used, the system can estimate both azimuth and elevation angles \cite{sandeep2018}.

While these systems allow superb performance they are also very expensive and require a lot of processing power.
Therefore this thesis works with a simpler and older solution -- a system with single RX antenna and TX antenna where radar is pointed to given direction mechanically.
This approach is not only cheaper but also allows to gather information about whole 3D space with just a single radar.

\section{CFAR}


CFAR is a simple algorithm that enables basic target detection in noisy radar data.
For each range bin its neighborhood is analyzed and the average power level is calculated.
This neighborhood is separated by a number of guard cells from the cell under test that don't partake in the calculation.
In case bin under test is greater than the scaled average power level of the neighborhood, we can assume that there is a target present \cite{jankiraman2018}.

There are many different variations of CFAR, each with its own advantages and disadvantages.
What was described is a basic cell averaging CFAR (CA-CFAR).
This algorithm works best in homogeneous environments, where the noise level is relatively constant across the neighborhood.
In case this cannot be assumed for example CFAR with greatest of the neighborhood (CAGO-CFAR) can be used.
This algorithm works by taking the maximum value of the neighborhood and comparing it to the bin under test instead of mean \cite{rohling1983}.

\chapter{\sidar}

Indie Semiconductor's \sidar is an FMCW radar system development kit designed primarily for automotive applications.
Out of the box, it offers two headers a 24~GHz and a 122~GHz both based on ICs from Indie Semiconductor (TRX-024-007 and TRA-120-001, respectively).
Both are strictly SISO ICs with two antennas -- one for receiving another for transmitting so azimuth estimation from phase shift is not possible.

\begin{figure}[h!]
  \centering
  \includegraphics[width=0.6\textwidth]{../img/sidar.png}

  \caption[\sidar  24~GHz configuration \cite{sidarMANOld}]{\sidar  24~GHz configuration \cite{sidarMANOld}}
  \label{fig:sidar}
\end{figure}

Direct communication with the radar header is not possible, or at least, the communication interface is undocumented.
Instand there is always and intermediary in the form of  STM32 Nucleo series microcontroller.
To this microcontroller does the user connect either directly with UART over USB or with WiFi enabled by on-board ESP32.
Both are relatively low bandwidth communication -- the serial maxing at baudrate of 1~000~000 \cite{sidarMAN}.

\begin{figure}[h!]
  \centering
  \includegraphics[width=0.7\textwidth]{../img/sidar_flow.png}
  \caption[Flow of Radar Measurement on \sidar \cite{sidarPRO}]{Flow of Radar Measurement on \sidar \cite{sidarPRO}}
  \label{fig:sidarFlow}
\end{figure}

The devkit is designed for easy integration into existing projects; however, this unfortunately poses limitations for this thesis.
In normal operation, the radar system functions as a black box (processing schema shown in \ref{fig:sidarFlow}), implementing its own filtering, FFT, and CFAR algorithms while only reporting a target list to the user.

This entire sequence can be triggered either internally (driven by a configurable oscillator) or externally (via a GPIO pin or UART input).
Once trigger is received the device carries out a user configured number of chirps.
The chirp length is determined by the number of sampling steps and the ADC sampling time as follows:
\begin{equation}
  t_\mathrm{ramp} = \frac{t_\mathrm{ADC} \cdot  (N_\mathrm{samples} + 85)}{36\,\, \mathrm{MHz}} \,\, \mu\mathrm{s},
  \label{eq:sampling}
\end{equation}
with the manufacturer recommending an optimal time of 1~ms for good SNR \cite{sidarPRO}.

SiRad is design to leverage coherent averaging to improve SNR of the output signal where multiple ramps are broadcasted and averaged.
While this technique was found to significantly aid in measurement in a cluttered environments averaging effectively destroy the information about the Doppler shift.
Additionally, due to the devkit's limited computational resources instead of sawtooth waveform radars broadcasts a segmented one with significant delays in between\cite{sidarPRO}.

The devkit is also clearly designed primarily for range measurement with little to no regard payed for speed calculation.
Not only are chirps spaced with large delays (at minimum some 20~ms) but the radar doesn't even maintain constant intervals between chirps.
This is the case even when relying on manual triggering of the radar, when using radar's self trigger results are even worse.

When measuring reporting interval with 20~ms trigger the radar achieved average time between updates of 20.5~ms with standard deviation of 1.3~ms.
However from time to time they were outliers when report came in only after 30~ms in the worst case or just 16~ms in the best case.
This was on relatively small dataset of 5000 samples.
In order to rule out that the problem isn't only in reporting output signal from the radar was captured by Rohde \& Schwarz FSW26 Signal and Spectrum Analyzer.
By analyzing some 40 samples, measured with the same trigger interval of 20~ms, average time between chirps was 20.7~ms with standard deviation of 0.7876~ms thus proving broadcast itself is irregular.

Unfortunately as the radar doesn't maintain constant intervals between chirps speed measurement precision is severely limited.
This could be partially mitigated if we knew when the chirp was broadcasted, giving us ability to introduce a correction.
However no such information is provided by the radar.
Thus each chip is timestamp with it's time of arrival which is assumed to be the time of chirp broadcast.
Respectively broadcast took time a trigger period before but this shift is irrelevant to the outcome.
Using this timing information speed spectrum can still be estimated using non-uniform DFT.

Per radars manual \cite{sidarPRO} following equation was used to calculate width of a single range bin
\begin{equation}
  \Delta R = \frac{c_0 (N+85)}{2\cdot BW\cdot NFFT},
  \label{eq:rangeBin}
\end{equation}
where variable $N$ denotes number of samples and $NFFT$ number of DFT points used to calculate the spectrum.
Except the corrective constant of 85 it closely follows the formula (\ref{eq:distance3}).

As for velocity the manufacturer doesn't recommend any formula so (\ref{eq:Doppler3}) was used with $T_\mathrm{ch}$ substituted by user-chosen trigger period.
However as the minimal period of chirps is still rather high not to mention the radar doesn't maintain constant intervals between chirps, the velocity measurement is not very practical.
Were we to use 24~GHz header with 25~ms trigger we get maximal speed of 0.124~m/s and on low 8 NFFT steps the resolution is only $0.031$~ms$^{-1}$.

This lack of perforace severely limits the radar's usability with regard to surveillance applications.
Most surveillance radars are designed to monitor dynamic environments, where targets is moving.
And usually at much higher speeds than the \sidar can measure.
This radar is completely unsuitable for such applications and is mainly applicable to static environments.
For example at parking lot, operator can detect if a car is parked in a given spot or not.
However beside such binary information about presence of a target and its distance not much more can be said.

\section{Outline of the Chosen Configuration }


For the purpose of this project, the devkit was configured to output raw data from the 12-bit ADC in the form of in-phase and quadrature components of the signal.
This allows for a more complex processing than if spectrum was calculated on the radar itself.
For these reasons, the default windowing and signal filtering were also disabled.
Device was set up to be triggered by command sent over UART.

Another parameter to consider in relation to surveillance application is AGC.
Using it adds two additional ramps that are used solely to set gain value leading to some 3~ms delay.
However bigger problem is the fact that radar doesn't report the gain value.
Using AGC could then lead to situations where weighting of the data is not constant during operation.
Thus it was deemed safest to turn AGC off and set the gain manually depending on how the readings appear after processing.

It is also important to note that the radar system is not well-suited for on-the-fly configuration changes.
Applying a new configuration takes some time  and the radar does not provide any feedback to indicate when a new configuration was applied.
As a result, commonly used techniques such as alternating chirp slope are not feasible.

In regards to the output format, the radar system supports two options: binary and TSV.
Since the output speed does not differ significantly between the two, the primary deciding factor was ease and speed of parsing.
Even when MATLAB is not particularly optimized for parsing binary data, it still processes binary output approximately 40\% faster than human-readable TSV data.

Other parameters such as sampling frequency, number of samples and so on are left to the user to configure.
Setting these strongly depends on what header is used and what environment is the radar used in.
Thus making their configuration static wouldn't be a good idea.


\section{24~GHz Header}

Center of 24~GHz header is a SISO TRX-024-007 transceiver which integrates low noise amplifier, frequency mixer, filters and VCO into a single chip.
It is primarily designed to operate in the ISM band (24.0--24.25GHz), but also support an additional ultra-wideband mode with frequency range from 23~GHz to 26~GHz \cite{sidarTRX24}.
On the \sidar there is no distinction made between  those two modes and the user is free to set any bandwidth \cite{sidarPRO} .
The transmitter output power ranges from 2.5~dBm to 6~dBm, depending on the configuration \cite{sidarTRX24}.
A maximum range of 400~m is advertised \cite{sidarMANOld}, though this is likely under ideal conditions when observing a large target.

As shown in figure \ref{fig:sidar}, the chip is connected to two microstrip patch antennas.
The patches are arranged in a relatively standard configuration, forming a 6×4 array with spacing approximately equal to half the wavelength at 24~GHz.

Since the manufacturer did not provide any information about the radiation pattern of the array, a simulation was conducted using the CST simulation suite.
Additionally, the manufacturer did not disclose the substrate parameters for the radar board specifically.
Fortunately, the TRX-024-007 datasheet includes a board stack-up for the chip's evaluation board.
It was assumed that the same stack-up would be used -- 18~$\mu$m copper for the traces and ground plane, with a 250~$\mu$m thick Rogers RO4350B substrate \cite{sidarTRX24}.

\begin{figure}[ht!]
  \centering
  \includegraphics[width=0.6\textwidth]{../img/boundaries.png}
  \caption[Simulated 24 GHz header with boundary conditions showed]{Simulated 24 GHz header with boundary conditions showed}
  \label{fig:boundaries}
\end{figure}

After measuring the dimensions of the array using an optical microscope, the entire array was redrawn in CST Studio.
Figure \ref{fig:boundaries} shows the applied boundary conditions: the antenna was placed in open space, and an $H=0$ condition was set along the symmetry plane to speed up the simulation.

After performing a standard time-domain simulation with an excitation signal ranging from 0 to 26GHz, the antenna array exhibited a minimum reflection coefficient $s_{11} \doteq -26.4 \mathrm{~dB}$ at 23.478~GHz with second minimum at 24.518~GHz (Figure \ref{fig:s11}).
Lack of minimum at 24~GHz may be attributed to difficulties measuring trace widths and distances (The etching quality of the copper traces was suboptimal.) and the neglecting interactions of different PCB board layers.

At both frequencies with minimal reflection, a far-field radiation pattern was calculated.
For clarity, only the 24.518~GHz pattern is shown in Figure \ref{fig:farfield3d}.
The main lobe width was measured at approximately 16 degrees (Figure \ref{fig:farfield180}) along the 180-degree norm (for orientation refer to the red cone on the PCB visualization), with a peak gain of 18.6~dBi and side-lobe suppression of -13~dB.
For the 90-degree norm, the main lobe width (Figure \ref{fig:farfield90}) was 30 degrees, with side-lobe suppression of -10~dB.

It's clear that especially in the 90-degree norm the accuracy isn't very good.
Thus this header is not suitable for applications where accurate elevation information is needed.
However if only low degree of accuracy is required or where wider field of view would be beneficial, this header is a good choice.
Especially as the radar can gather more information about the environment faster than one with narrower beam.
In industry some surveillance radars are also designed to have a wide beam in elevation.
Such as some Air Traffic Control radars \cite{kratos} or even some ground radars \cite{blighter}.
Still usually solutions such as low/high beam switching are preferred instead of relying purely on a wide beam \cite{wolfBeam}.

\begin{figure}[h!]
  \centering
  \includegraphics[width=0.9\textwidth]{../img/s11.png}
  \caption[$s_{11}$ parameter of the 24~GHz header]{$s_{11}$ parameter of the 24~GHz header}
  \label{fig:s11}
\end{figure}


\begin{figure}[h!]
  \centering
  \includegraphics[width=0.43\textwidth]{../img/farfield3d.png}
  \caption[Radiation pattern of 24~GHz header -- 3D view]{Radiation pattern of 24~GHz header -- 3D view}
  \label{fig:farfield3d}
\end{figure}

\begin{figure}[h!]
  \centering
  \includegraphics[width=0.9\textwidth]{../img/farfield180.png}
  \caption[Radiation pattern of 24~GHz header -- 180° norm]{Radiation pattern of 24~GHz header -- 180° norm}
  \label{fig:farfield180}
\end{figure}

\begin{figure}[h!]
  \centering
  \includegraphics[width=0.9\textwidth]{../img/farfield90.png}
  \caption[Radiation pattern of 24~GHz header -- 90° norm]{Radiation pattern of 24~GHz header -- 90° norm}
  \label{fig:farfield90}
\end{figure}


\section{122~GHz Header}


\begin{figure}[h!]
  \centering
  \includegraphics[width=0.85\textwidth]{../img/sidar122rad.jpg}
	\caption[Radiation pattern of 122~GHz header comparison \cite{sidarTRX122col}]{Radiation pattern of 122~GHz header comparison \cite{sidarTRX122col}}
  \label{fig:sidar122rad}
\end{figure}

The 122~GHz header is based on the TRX-120-001 transceiver, which, in addition to the essential components required for RF transmission and reception, also incorporates two on-chip antennas.
It's designed to operate in the 122-123~GHz band, with output power ranging from -7~dBm to 1~dBm \cite{sidarTRX122}.
The chip is capable of detecting large targets at distances of up to 40~m \cite{sidarMANOld}.

Out of the box performance of the system is quite bad (Figure \ref{fig:sidar122rad}) with width of the main lobe being roughly $\pm40\text{°}$ in both E-plane and H-plane \cite{sidarTRX122}.
However, this can be significantly improved using the supplied collimator lens, reducing the main lobe width to $\pm4\text{°}$ \cite{sidarTRX122col} (see Figure \ref{fig:sidar122rad}).





\chapter{Rotary Platform}

Following chapter outlines design process and the operation of a rotary platform specifically designed for \sidar radar system.


\section{Platform Construction}

As the platform needs to transmit data from the rotating section to the stationary base, a slip ring is required.
Due to the relatively low transmission speed of the radar and the absence of special requirements such as waterproofing, an affordable model, UH3899-01-0810 from Senring, was selected.
It is a classical contact slip ring that features a dedicated USB~2.0 connection along with 8 additional signal wires, with an advertised insertion loss of less than 2~dB \cite{slipring}.
More problematic than loss is however cross talk between signal wires when pitch control stepper motor is running.
This necessitated an addition of small capacitor to the endstop signal wire to filter out high frequency noise.

While USB~2.0 connection doesn't seem affected by the crosstalk it's connection still isn't ideal.
Without signal conditioner connected directly to the slipring output signal quality is bad enough that direct connection to PC is needed -- thus radar needs to be some 20~cm from the PC.
And even then depending on PC's USB port wiring some ports might exhibit issues.
In addition the manufacturer opted for a non-standard male-male USB~2.0 connection, requiring a female-female adapter to connect the radar to the slip ring.

Due to the relatively low angular resolution of the radar, high platform precision was not a requirement.
A basic 200-step stepper motor with a step size of 1.8\text{°} was deemed sufficient.
In case user would require more granular control over the position it can be facilitated by microstepping.

Similarly high-speed movement is unnecessary for this application.
As was already outlined the radar is capable at best of some 50~Hz update rate.
With such update frequency even at low 8~RPM we travel a degree under 21~ms -- any waster and we wouldn't get at least one update for each degree.
At these RPMs standard 40~mm NEMA17 stepper motors are powerful enough to turn the rather stiff splipring.

The rest of the design is relatively simple.
Fixed section mounts the slipring with a stepper motor positioned underneath, directly driving a shaft connected to a rotating base.
The connection is secured using long M4 set screws that pass through the base, through the slip ring and hold the shaft in place.
A 3D-printed housing serves only as a centering guide and is not under any load from shaft connection.

The rotating section features a simple A-frame design that elevates the radar, which is mounted on two ball bearings, allowing it to tilt freely.
To control the pitch, a second stepper motor is mounted on the rotating platform and linked to the radar via a 2:1 down-gearing ratio using a standard 8~mm belt.
An optical endstop, used for homing of the platform, is attached on the second support strut.

Unfortunately while the design offers some ability to tension the belt in currently printed configuration the adjustments range is not sufficient to fully tension the belt.
While slippage is not a problem there is some slack in radar's tilt.
However as the radar's capabilities in pitch direction aren't particularly high it was decided not to reprint the whole assembly, only to fix issue in supplied 3D models.

Given that mechanical stresses are minimal, most parts can be 3D-printed using standard PLA filament.
The only non-3D-printed components are the screws, bearings, and stepper motors.
The final assembly (Figure~\ref{fig:side_by_side}) measures approximately 36~cm in height and has a footprint of roughly $20\times20$~cm.

\begin{figure}[h!]
  \centering
  \begin{subfigure}[b]{0.45\textwidth}
    \centering
    \includegraphics[width=\textwidth]{../img/whole_assembly_2.png}
    \caption{3D render}
  \end{subfigure}
  \hspace{0.05\textwidth} % Adjust spacing
  \begin{subfigure}[b]{0.45\textwidth}
    \centering
    \includegraphics[width=0.75\textwidth]{../img/assembly_photo.jpg}
    \caption{Photo}
  \end{subfigure}
  \caption{Form of the final assembly}
  \label{fig:side_by_side}
\end{figure}


\subsection{Platform Electronics}

Electronic side of the platform is relatively simple.
Only two main problems needed to be tackled -- driving the stepper motors and implementing a homing mechanism.

Given the low load on the stepper motors and the platform's inability to accumulate significant momentum, a basic stepper driver without feedback control was deemed sufficient.
For this purpose the A4988 stepper driver was chosen due to its low cost, microstepping capabilities and basic current control \cite{a4988}.
A minor drawback is the lack of any feedback from the driver to the microcontroller, including stall detection.
To simplify the design, A4988 development kits were used and soldered onto a prototyping board, eliminating the need for a custom PCB.
In addition if the need arieses A4988 development kit can be replaced by one with a different IC, such as TCM2209, as manufacturers keep the same pinout and dimensions on these.
This might be necessary in application where platform loudness would be a serious problem as A4988 produces rather noisy driving signal.
More modern drivers exhibit even 20~dB lower noise levels \cite{a4988_sound}.

For homing implementation, two potential solutions were considered: Hall effect sensors and optical gates.
Hall effect sensors offer the advantage of angle sensing, allowing correction for positional drift during operation; however, they require precise alignment.
If the orthogonal Hall effect sensor is not perfectly placed along the axis of rotation, calibration becomes necessary \cite{hall}.
While feedback would be beneficial, the microcontroller already tracks each step taken by the motor during normal operation, making it possible to determine the platform's position purely in software.
Thus for simplicity and ease of integration, optical gates were selected.

The system is controlled by an ESP32 microcontroller.
The ESP32-C6 version was chosen due to the author's extensive experience with this particular model.
Still since the system does not require specialized peripherals or high processing power most other microcontrollers could have been use instead.

\section{Platform Software}

Given its widespread adoption as an industry standard for controlling similar machines, G-code over serial is a natural choice for the platform's communication format.
Beyond the basic functionality typically offered by G-code interpreters, the platform must support additional features to reduce the user's manual control burden.
These features include common features like defining movement limits, absolute/relative positioning mode, spindle mode or enabling automatic homing.
Lastly the platform should support a programming interface that will allow application to send whole choreography of movements to the platform at ones and from that point only monitor its status.

For uplink communication, the platform must provide real-time information about its current position and speed.
This data enables the user to make any mathematical corrections and properly interpret radar's gathered data.

To maximize efficiency in processing commands and ensure accurate stepper motor control, the program workflow is divided into three distinct layers, as illustrated by figure \ref{fig:code_diag}.
The commonly used two-component architecture -- where one component handles communication/command parsing and the other manages execution was deemed unsuitable for this use case.
Such approach would complicate integration of programming interface and require just-in-time processing of commands, which could lead to performance issues.

In the chosen architecture, the degree of abstraction decreases with each successive layer, simplifying processing at each step.
This design allows the final layer to operate with maximum efficiency, where transition from one command to next is next to instantaneous.

It is necessary to note that the platform doesn't store any permanent configuration, including microstepping settings
This approach was taken as platform doesn't offer any easy way to show current setting and is expected to be only operated from computer application.
Thus instead of needing to keep track of what settings are on PC, what are stored on the platform simpler approach was taken.

\begin{figure}[h!]
  \centering


  \begin{tikzpicture}[scale=0.9, node distance=1.5cm]

    % Layer headers
    \node (comm_layer) [layerheader] at (0, 0) {Communication Layer};
    \node (app_layer) [layerheader] at (6, 0) {Application Layer};
    \node (hal_layer) [layerheader] at (12, 0) {HAL Layer};

    % Communication Layer
    \node (comm_start) [startstop, below of=comm_layer, yshift=-0.3cm] {Start};
    \node (wait_serial) [process, below of=comm_start] {Wait for serial data};
    \node (parse_gcode) [process, below of=wait_serial] {Parse G-code};
    \node (parse_success) [decision, below of=parse_gcode, align=center, yshift=-1.3cm] {Parsing\\ Successful?};
    \node (store_command) [process, below of=parse_success, align=center, yshift=-1.8cm] {Store command\\ queue ? program};
    \node (send_response) [process, below of=store_command,yshift=-0.25cm] {Send response};

    % Arrows in Communication Layer
    \draw [arrow] (comm_start) -- (wait_serial);
    \draw [arrow] (wait_serial) -- (parse_gcode);
    \draw [arrow] (parse_gcode) -- (parse_success);
    \draw [arrow] (parse_success.east) -- ++(1, 0) |- (send_response.east) node[midway, left, yshift=+0.25cm] {No};
    \draw [arrow] (parse_success.south) -- ++(0, -0.5) -| (store_command.north) node[midway, right, yshift=+0.05cm] {Yes};
    \draw [arrow] (store_command) -- (send_response);
    \draw [arrow] (send_response.west) -- ++(-0.5, 0) |- (wait_serial.west);

    % Application Layer
    \node (app_start) [startstop, below of=app_layer, yshift=-0.3cm] {Start};
    \node (update_position) [process, below of=app_start] {Update position};
    \node (check_queues) [decision, below of=update_position, yshift=-1.3cm] {Queues full?};
    \node (load) [process, below of=check_queues, align=center, yshift=-1.5cm] {Load command \\ queue ? program};
    \node (process_command) [process, below of=load,yshift=-0.25cm] {Process command};
    \node (store_command) [process, align=center, below of=process_command] {Add command \\ to stepper queue};

    % Arrows in Application Layer
    \draw [arrow] (app_start) -- (update_position);
    \draw [arrow] (update_position) -- (check_queues);
    \draw [arrow] (check_queues.east) -- ++(1, 0) |- (update_position.east) node[midway, left, xshift=0.2cm, yshift=+0.25cm,xshift=0.2cm] {Yes};
    \draw [arrow] (check_queues.south) -- ++(0, -0.5) -| (load.north) node[midway, right, yshift=+0.1cm] {No};
    \draw [arrow] (load.south) -- ++(0, -0.5) -- (process_command.north);
    \draw [arrow] (process_command) -- (store_command);
    \draw [arrow] (store_command.west) -- ++(-0.5, 0) |- (update_position.west);


    \node (hal_start) [startstop, below of=hal_layer, yshift=-0.3cm] {Start};
    \node (wait_queue) [process, below of=hal_start] {Wait on queue};
    \node (execute_command) [process, below of=wait_queue] {Execute command};
    \node (wait_command) [process, below of=execute_command] {Wait on command};
    \node (update_info) [process, align=center, below of=wait_command] {Update last \\command};

    % Arrows in HAL Layer
    \draw [arrow] (hal_start) -- (wait_queue);
    \draw [arrow] (wait_queue) -- (execute_command);
    \draw [arrow] (execute_command) -- (wait_command);
    \draw [arrow] (wait_command) -- (update_info);
    \draw [arrow] (update_info.west) -- ++(-0.5, 0) |- (wait_queue.west);

  \end{tikzpicture}

  \caption[Program flow diagram]{Program flow diagram}
  \label{fig:code_diag}
\end{figure}

\subsection{Communication Layer}

The communication layer processes incoming data over the serial line.
Whose efficient handling is facilitated with the aid of RTOS queues.
Upon receiving command, string is parsed and either pushed to a queue to be executed or added to a programm declaration, in case user is currently writing a program.
Some special commands are executed immediately, like those enabling emergency shut off.
For complete overview of supported commands consult Appendix A.

Immediately after the parsing, a response is send to the user confirming whether the command was parsed correctly or not.
However, as the communication layer does not a can not check command within context of all previous commands, it is possible that command will be parsed correctly but its execution will fail in the application layer.

\subsection{Application layer}

The application layer performs two primary functions: tracking current device position and scheduling commands to be sent to stepper motors.
Aside from current position the program also keeps track of the end position of the last scheduled command.
Thanks to this the application layer is able to make all necessary calculations to facilitate absolute positioning or enforce movement limits.

Key departure from standard G-code interpreters, like \cite{duet}, is how the platform handles single-axis move commands.
When a move command targets only one axis, the other axis remains free to read a next command and begin its execution.
If this behavior is undesirable, the user must issue commands for both axes simultaneously.
In relative positioning mode, a zero value results in no motion; in absolute positioning mode, the command must specify the current position to prevent movement.

This behavior is a necessary side effect of the spindle regime, which typically cannot be toggled on or off dynamically.
Another consequence of spindle mode is the requirement for separate positioning modes for each axis.
Continuous rotation prevents calculating a move’s end position, making it impossible to make calculation for absolute positioning commands -- thus necessitating relative positioning.
However it would be rather restrictive to force user to relative positioning on second axis, therefore the independent positioning modes.

In order to support other possible applications a manual override mode was also implementing.
This enables the user to manually push a move command directly to stepper queues totally skipping the application layer.
Primary usecase of this mode is to allow tracking of targets or usee in other application that require real time control over the platform.
However in this regime no limits are enforced and the platform operates strictly in relative positioning mode.

\subsection{HAL Layer}

The final layer manages stepper motor control and provides the application layer with essential data for position calculations.
In its loop, the program waits for the next command in the stepper queue.
Upon receiving a command, it sets up execution, waits for one or both steppers to complete their movement, and then proceeds to the next command.
Since limit and absolute positioning and limits calculations are handled in the application layer whole routine remains highly efficient -- layer just moves given number of steps.

The main challenge was a generation of precise PWM signals (Used to control stepper motors drivers.) and stopping the signal generation after a specific number of steps.
As generating PWM signal in software is unpractical dedicated EPS32C6 peripherals needed to be leveraged.
There are two main options for this task: Remote Controlled Transceiver (RMT) and Motor Control Pulse Width Modulation (MCPWM) combined with Pulse Counter (PCNT).
While RMT allows smooth PWM frequency adjustments, it has several drawbacks.
Such as the fact that generating a specific number of pulses is supported only on newer ESP32 models \cite{gitRMT}, synchronization is restricted to its proprietary API and there is no straightforward way to track progress during a move \cite{espRMT}.

For these reasons, MCPWM and PCNT were chosen.
MCPWM handles pulse generation, while PCNT counts steps, enabling easy control over the movement and providing robust API for step count tracking \cite{espPCNT}.
The only limitation is the PCNT’s 15-bit counter, which caps the maximum steps per move at $\pm$32,767.


\subsubsection{Performance of the HAL Layer}

Table \ref{tab:performancepwm} illustrates the stability of PWM generation by the MCPWM module at various speeds.
Measurements were conducted using a Saleae Logic Pro 16 logic analyzer, with no microstepping enabled.

The results show that frequency deviation is minimal, though the generated speed is consistently marginally faster than the target, and  the error increases slightly with higher speeds.
Nevertheless, when measuring time of 24,000 steps at 120 RPM, the relative error in time duration (or speed) was only $\epsilon = -0.004\%$, demonstrating excellent accuracy.


\begin{table}[h!]
  \centering
  \caption[Stability of PWM generation]{Stability of PWM generation}
  \begin{tabular}{| m{2cm} || m{2.5cm} | m{2.5cm} | m{2.5cm} | m{2.5cm} |}
    \hline
    RPM & $f_{\mathrm{desired}}$ (Hz) & $f_{\mathrm{low}}$ (Hz) & $f_{\mathrm{high}}$ (Hz) & $f_\mathrm{avg}$ (Hz) \\
    \hline
    10  & 33.334                      & 33.334                  & 33.334                   & 33.334                \\
    30  & 100                         & 100                     & 100.003                  & 100.002               \\
    60  & 200                         & 200                     & 200.01                   & 200.004               \\
    120 & 400                         & 400                     & 400.02                   & 400.007               \\
    \hline
  \end{tabular}
  \label{tab:performancepwm}
\end{table}

\begin{figure}[h!]
  \centering
  \includegraphics[width=\textwidth]{../img/120rpm_to60_1.jpg}
  \includegraphics[width=\textwidth]{../img/120rpm_to60_2.jpg}
  \caption[Moment of change between commands with 120RPM and 60RPM]{Moment of change between commands (120RPM $\Rightarrow$  60RPM)}
  \label{fig:switching}
\end{figure}

An attempt was made to also measure the delay  between switching commands, displayed in figure \ref{fig:switching}.
The results indicate that the delay between commands is imperceptible.
Similar outcomes were also observed for other command combinations.

This demonstrates the efficiency of the HAL layer in managing stepper motor control and transitioning seamlessly between commands.
As long as stepper queues are supplied with commands in advance, the platform can operate without noticeable interruptions.



\chapter{Control Application}

As previously stated control application for the whole system is written in MATLAB.
There are two main distinct parts - one is managing the platform and the other is processing radar data.
Alongside these there are some shared components, such as preferences menu.

\section{Main Window}

Upon starting the application user is presented with a main window (Figure \ref{fig:main_window}).
This window is primarily used to display radar data and control basic functionality of the application.
On the sidebar user can enable serial connections to the radar and the platform, pause processing, save current visualization to jpg and stop the platform in case of an emergency.
Lastly topbar is used to access preferences and platform control interface.

\begin{figure}[h!]
  \centering
  \includegraphics[width=0.9\textwidth]{../img/vis_range_azimuth.jpg}
  \caption[Main application window]{Main application window}
  \label{fig:main_window}
\end{figure}

\subsection{Application Configuration}

As this thesis concerns itself with rather generic implementation of surveillance radar system the application is designed to be as flexible as possible.
For this purpose GUI menu was designed to enable configuration of all important elements - configuring the platform, radar, data processing and data visualization.
However it is necessary to point out that given extensive configuration options user is expected to have some knowledge about the subject to achieve satisfactory results.
Firstly -- configuration options aren't checked against each other to verify if they aren't mutually exclusive.
For example for speed calculation ramp averaging must be turned off, but as things stand application will allow user to continue even with it on.
Secondly -- configuration of components such a CFAR or DBSCAN strongly depended on bandwidth, samples, FFT point count and other parameters.
CFAR guard parameter of 3 might be too small on 5~GHz bandwidth with width of single range bin of 50~mm, but if with $BW=500$~MHz it could be way too large.
To aid with choosing correct parameters the application provides some basic information like dimensions of the bins; however it is up to the user to make the final decision.

Figure \ref{fig:preferences} shows the preferences menu, as one can see there are four main sections.
First configures serial port connections to the radar and the platform.
Second section handles configuration of the platform, followed by a section designated for radar configuration.
Last section configures how the data are processed and via which method they are visualized.

\begin{figure}[h!]
  \centering
  \includegraphics[width=0.7\textwidth]{../img/preferences.jpg}
  \caption[Preferences menu]{Preferences menu}
  \label{fig:preferences}
\end{figure}

User's preferences are stored in a INI file format in directory whose path depends on used operating system -- \texttt{\%APPDATA\%/Local/fmcw/fmcw.conf} on Windows and \texttt{\$HOME/.config/fmcw/fmcw.conf} for unix based systems.
As INI format is easily human readable it is possible to edit the file directly.


\section{Platform Control Interface}

It is necessary to emphasizes that the platform control is entirely independent of the radar operation.
User loads up program to the platform, starts its execution.
From then application is only processing current position reports comming from the platform.
There is no feedback from the radar to the platform based on processed data, although as the platform enables direct access to the stepper queues it would be possible to implement such a feature.
Nor does processing take into account from which movements is a platform's current program comprised.

In preferences menu user can configure static offsets to the platform with the \texttt{Pitch offset} and \texttt{Yaw offset} options.
This is useful in case zero position of the platform is not aligned with what user want's to be zero in data.
Aside form offset step count configuration is also available here with \texttt{Step count pitch} and \texttt{Step count yaw}.
Step count takes into accoun both microstepping and physical down gearing ratio.
It is important to note that as the platform doesn't store step count in non volatile memory this setting is essential to maintain propper operation of the platform.
The step count command is sent to the platform each time it is connected or config is changed.
Lastly \texttt{Platform debug} toggle enables full debug output to be visible in platform control window.

\begin{figure}[h!]
  \centering
  \includegraphics[width=\textwidth]{../img/platform_control.jpg}
  \caption[GUI of the platform control]{GUI of the platform control}
  \label{fig:platformControl}
\end{figure}

Managing platform programs is done via a separate window (Figure \ref{fig:platformControl}).
This interface enables user to load, edit and send programs to the platform.
Left sidebar allows user to load stored programs by clicking on their name.
Middle text boxes are used to edit programs header (top part) and program body (middle part) with bottom text field being used to display platforms debug output.
On the right side are then buttons that handle basic operations over program -- load, save, store to file, upload and start.

Commands are written one per line, their complete syntax is described in Appendix A.
Control commands used to denote start of program, end of header and so on are automatically sent to the device when rest of the program is uploaded.
To validate whether program was parsed correctly user can consult the text window at the bottom of the screen which forwards platforms debug output to the user.
In case user clicks the store button the program is stored in same INI file as preferences.


Backend side of the platform control is rather straightforward.
After connection is established MATLAB serial interface calls a callback each time terminator sequence is found in received data.
Received message is then parsed with debug output being forwarded to the user and positions logged with timestamp in a circular buffer.
Radar data processing part can then request a list of positions for given time interval.

Platform control can also emit an event when platform finds itself close to a predetermined position.
This location is specified in option \texttt{Reset yaw} with tolerance zone fixed at two degress on either side.
In order to prevent multiple triggering of the event the platform will only emit it once per 1~s.
This event allows reset of stored data after cycle is completed when \texttt{Cube decay} option is set to reset.

\section{Radar configuration}

Given that the radar's output is displayed in the main window there isn't any specialized interface dedicated just to the radar.
Still in preferences menu there are some paramters that can be configured.

\texttt{Radar frequency} toggle chooses between 24~GHz and 122~GHz header.
However this only affect configuration sent to the radar, it doesn't reflash the firmware what is also necessary to do.
After base frequency \texttt{Radar bandwidth} can also be configred, both positive and negative values are accepted however manual verification is required to verify that the radar is working as expected.
While manufacturer states a 3~GHz limit on the 24~GHz header and 5~GHz on the 122~GHz header \cite{sidarPRO}, in practice, especially with the 24~GHz header, achievable bandwidth was usually much lower and its limit rather inconsistent.

User can also configure number of samples per chirp via \texttt{Chirp samples} and ADC rate with \texttt{ADC ClkDiv}.
These two paramters determine time of a single ramp which is calcualted with equation (\ref{eq:sampling}).
Together with gain, ramp time plays a crutial role in maintaining good signal-to-noise ratio.

Drop down menu \texttt{Ramp coherent avg} allows user to pick how many ramps will be averaged together.
However use of this feature is generally not recommended unless surrounding environment is too cluttered (such as in a lab).
Each ramps adds some 2~ms overhead to the radar's operation and makes speed calculation impossible.


Last paramters is \texttt{Trigger period} which dictates how often will the application send a trigger command to the radar.
As previously stated the radar is at best capable of around 50~Hz update rate or 20~ms per chirp.


\chapter{Radar Data Processing}

Firstly it is necessary to outline what inputs and outputs of the whole processing pipeline are.
Data to the application comes from two sources - serial connections to the radar and to the platform.
These two streams are then paired together based on timestamps logged when data is received.
Processing then does user chosen calculations -- parts such as CFAR calculation, speed calculation and so on can be turned on or off.
After that output data are stored in a radar cube, common method to manage radar's data that enables easy integration of more complex algorithms in the future \cite{richards2022}.

Given that both CFAR and raw data (That is individual range-Doppler maps.) calculation might enabled at the same time application has two radar cubes.
One is a 4D structure with dimensions of fast time $\times$ slow time $\times$ yaw $\times$ pitch, used to store complete range-Doppler map for each spatial degree.
In this thesis this structure is only used for visualizing of raw data for given fixed pitch angle or showing range-Doppler map for given yaw and pitch.
Any 3D visualization style of the raw data would be too cluttered and hard to interpret.
Second cube is a 3D structure with dimensions of range $\times$ yaw $\times$ pitch, this one is used to store CFAR output.

In each case yaw resolution is fixed 1 degree thus the cube is 360° wide.
Given quality of radar mounting bracket, 1.8° resolution of stepper and tighthness of radiation pattern 1° degree was deemed sufficient.
As for pitch same resolution was kept with angles ranging form -20° to +80° being covered.
Lower bound is limited by the radar's mounting bracket and upper bound is more or less arbitrary, slightly motivated by trying to perevent radar from seeing behind itself.

Main complicating factor in the processing was a need to keep the main thread responsive.
Most time critical thing main thread is responsible for is timely readout of data from serial ports.
If data can't be read right after its arrival assigned timestamps will be wrong and therefore data will be attributed to wrong position.
In addition GUI starts to be quite unresponsive if resources of the main thread are stretched too thin.

To solve this problem processing heavily leverages MATLAB's Parallel Computing Toolbox, offloading as much as possible to different cores.
Thorough whole processing pipeline there are mechanism of buffering data into larger batches and if needed discarding some in case software is unable to keep up.
Unfortunately as MATLAB's parallelization capabilities with threads are rather limited  -- external language interface don't work, neither do certain file/memory mapping functions \cite{matlabParallel}.
Thus the parallelization needed to be done with processes.
This restrict the application to machines with at least 16~GB of RAM as each process (of which there are three) requires around 2~GB of RAM.

Procesisng pipeline can be divided into multiple distinct steps as follow:
\setlist[enumerate]{nosep, topsep=3pt, partopsep=3pt}
\begin{enumerate}
  \item Data acquisition: Data are read, simple FFT is calculated and sectrums are buffered into a circular buffer.
  \item Data processing: Spectrums are retrived from the circular buffer, paired with positions and processed.
  \item Cube update: Processed data are buffered into a ping-pong buffer. In case buffer is full the cube update routine is launched.
  \item Visualization: After cubes are updated data are visualized.
\end{enumerate}

\section{Data Acquisition}

Basic workflow of this step is showned on figure \ref{fig:radar_flow}.
Action starts as soon as MATLAB detects line terminator within incoming radar data stream.
After whole frame from the radar is read, data are timestamped and I and Q channels buffered.
Observer \texttt{dataProcessor.m} is then notified and left to retrieves the data when main thread is free.

After retrieval inphase and quadrature channels are merged to form an complex singal which is multiplied by a Hann window to prevent spectral leakage.
Basic 1D FFT is then calculated with number of points set by \texttt{Range NFFT} paramter in preferences.
In case fft order is larger than the number of samples zero padding is added.
Resulting spectrum is again buffered, as spectrums will be subjected to futher processing they are kept in original complex form.
Following this step program has in memory multiple FFT spectrums -- these can be leveraged to enable range-Doppler map computation.

After spectrum is stored program verifies if the platform has moved.
This check enables to save processing resources by not computing R-D map that would be immediately rewritten.
After movement code than takes all spectrums (Except the last one when the platform has changed position.) and launches another processing step in a separate thread.
In case user wishes for procesisng to always take place (e.g. they are verifying radar settings when platform is static) this position check can be skipped by toggeling \texttt{Require pos change}.

\begin{figure}[h!]
  \centering
  \begin{tikzpicture}[node distance=1.5cm, scale=0.6]

    % Layer headers
    \node (radar_header) [layerheader] at (0, 0) {radar.m};
    \node (processor_header) [layerheader] at (7.5, 0) {dataProcessor.m};

    % Radar Module
    \node (radar_start) [startstop, below of=radar_header, yshift=-0.3cm] {Start};
    \node (read_serial) [process, below of=radar_start] {Read serial data};
    \node (buffer_raw) [process, below of=read_serial] {Buffer raw data};
    \node (notify) [process, below of=buffer_raw] {Notify observers};

    % Data Processor Module
    \node (proc_start) [startstop, below of=processor_header, yshift=-0.3cm] {On notify};
    \node (read_radar) [process, below of=proc_start] {Read radar data};
    \node (calc_fft) [process, below of=read_radar, align=center] {Calculate FFT\\ Buffer spectrum};
    \node (check_pos) [decision, below of=calc_fft, yshift=-1cm, align=center] {Position\\ changed?};
    \node (get_spectrums) [process, right of=read_radar, xshift=4cm, align=center] {Get spectrums};
    \node (get_positions) [process, below of=get_spectrums] {Get positions};
    \node (cfar_process) [process, below of=get_positions, align=center] {Launch 2D/CFAR\\ processing};
    \node (proc_stop) [startstop, below of=check_pos, yshift=-1.3cm] {End};

    % Arrows for Radar Module
    \draw [arrow] (radar_start) -- (read_serial);
    \draw [arrow] (read_serial) -- (buffer_raw);
    \draw [arrow] (buffer_raw) -- (notify);
    \draw [arrow] (notify.west) -- ++(-1,0) |- (read_serial.west);
    %
    % % Arrows for Data Processor Module
    \draw [arrow] (proc_start) -- (read_radar);
    \draw [arrow] (read_radar) -- (calc_fft);
    \draw [arrow] (calc_fft) -- (check_pos);
    %
    % % Yes branch
    \draw [arrow] (check_pos.east) -- ++(1,0) node[right] {Yes} |- (get_spectrums.west);
    \draw [arrow] (get_spectrums) -- (get_positions);
    \draw [arrow] (get_positions) -- (cfar_process);
    %
    % % No branch
    \draw [arrow] (check_pos.south) -- node[right] {No} (proc_stop.north);

    % \draw [arrow] (cfar_process.south) -- ++(0,-1.7) -| (proc_stop.east);
    \draw [arrow] (cfar_process.south) |- (proc_stop.east);
  \end{tikzpicture}
  \caption{Processing flow - Data acquisition}
  \label{fig:radar_flow}
\end{figure}

\section{Data Processing}

This parallel process takes calculated FFT spectrums and their accompanying positions and processes them into single range-Doppler map and array with CFAR output.
Basic outline of the processing flow is shown in figure \ref{fig:feature_flow}.

\begin{figure}[h!]
  \centering
  \begin{tikzpicture}[node distance=1cm, scale=0.5]
    % Main horizontal flow
    \node (processor_header) [layerheader] at (0, 0) {dataProcessor.m};
    \node (start) [startstop, below =of processor_header] {Thread start};
    \node (rcs) [process, right = of start] {Calculate RCS};
    \node (cfar_decision) [decision, below = of start] {CFAR?};
    \node (raw_decision) [decision, right=1cm of cfar_decision] {RAW?};
    \node (speed_decision) [decision, right=1.5cm of raw_decision] {Speed?};
    \node (return) [startstop, below=2.6cm of speed_decision] {Return};

    % CFAR branch
    \node (cfar_proc) [process, below=of cfar_decision, align=center] {Calc\\CFAR};


    % Speed branch
    \node (mock) [process, below left=1.5cm and -0.4cm of speed_decision, align=center] {Use last chirp\\ RCS array};
    \node (fft) [process, below right=1.5cm and -0.4cm of speed_decision, align=center] {2DFFT/\\NUFFT};

    % Connections
    \draw [arrow] (start.east) -- (rcs.west);
    \draw [arrow] (rcs.south) -- ++(0,-1) -| (cfar_decision.north);
    \draw [arrow] (cfar_decision.east) -- node[above] {No} (raw_decision.west);
    \draw [arrow] (cfar_decision.south) -- node[right] {Yes} (cfar_proc.north);
    \draw [arrow] (cfar_proc.east)  -- ++(0.3,0) |- (raw_decision.west);
    \draw [arrow] (raw_decision.south) -- ++(0,0) node[left] {No} |- (return.west);
    \draw [arrow] (raw_decision.east) -- node[above] {Yes} (speed_decision.west);
    \draw [arrow] (speed_decision.south) -- ++(0, -0.5) node[above, xshift=-1cm] {No} -| (mock.north);
    \draw [arrow] (speed_decision.east) -- ++(0, 0) node[above, xshift=+0.5cm] {Yes} -| (fft.north);
    \draw [arrow] (mock.south) -- ++(0,0) |- (return.west);
    \draw [arrow] (fft.south) -- ++(0,0) |- (return.east);

  \end{tikzpicture}
  \caption{Processing flow - Data processing}
  \label{fig:feature_flow}
\end{figure}

In the first step last spectrum is converted to values proportional to the radar cross section of the target.
Starting with equation (\ref{eq:radar_eq}) we can see that the target's RCS is proportional to the received power divided by fourth power of the distance to the target.
Range can be calculated from manufacturer's supplied equation (\ref{eq:rangeBin}) and power is proportional to the square of values reported from the radar.
Given that constants of the radar equation changed based on configuration calibration would be required in ordet to get real RCS values.
However this calibration is not supported and thus onwards when refering to RCS we will be refering to the values proportional to the RCS and not real RCS of the object.

After RCS conversion if \texttt{Calc CFAR} is enabled CFAR algorithm will be executed on the latest chirp in the batch.
In this application simple 1D CA-CFAR from MATLAB's Phased Array System Toolbox is used which parametrized with two variables -- number of guard bins (Those are excluded from the average and are right next to bin we are testing.) and number of training bins (Those are used to calculate the average.) \cite{matlab_cfar}.
Both these paramters are configurable from preferences menu with \texttt{CFAR training} and \texttt{CFAR guard}.

If raw data calculation is enabled (Using \texttt{Calc raw cube} toggle.) the program takes one of two paths depending on whether speed calculation is toggled on or off with \texttt{Calc speed}.
In case speed calculation is disabled the program just returns half of the original spectrum converted to RCS.

When speed calculation is enabled program firstly cuts of samples that are too far away from the position of the latest chirp.
After that timing of chirps are analyzed to determin whether NUFFT need's to be used.
Decision which transformation to use is based solely on the ratio of maximal deviation of the chirp intervals to the median of the chirp intervals -- if this ratio is over 20~\% NUFFT is used.
For more accurate measurement more complex method should have been used but as the radar timing data are not very precise not to mention radar can track only very slow moving objects, this method was deemed sufficient.
For simmilar resasons no correction for the platform's movement is applied.
Output range-Doppler map is then shifted in order to get 2D array with \texttt{Range NFFT} $\times$ \texttt{Speed NFFT} number of elements with speed going from $-\frac{\text{Speed NFFT}}{2}\cdot w $ to  $\left(\frac{\text{Speed NFFT}}{2}-1\right)\cdot w $, where $w$ is speed bin widht calcualted with (\ref{eq:Doppler3}).


\section{Cube Update}

Last step of processing pipeline handles updates of radar cubes (Figure \ref{fig:cube_flow}).
Range-Doppler maps and CFAR data are firstly buffered in a ping-pong buffer -- where one is being used to update the cube while the other is being filled with new data.
Upon the buffer is filled they switch roles and cube update routine is launched.

As matlab processes do not share same memory space by default, in order not to have redundant copies of cube matlab's memory mapping is used.
Using function \texttt{memmapfile} the cube is mapped to a file on the disk which can be shared between two processes \cite{matlab_memory}.
This approach might lead to some performance degradation if the cube is too large and cannot be held in RAM but in testing it was found that for cubes of size 512MB (roughly cube for range-Doppler map of 256 $\times$ 16 ) the program was still able to keep up with the radar.


\begin{figure}[h!]
  \centering
  \begin{tikzpicture}[node distance=1cm, scale=0.5]
    % dataProcessor.m flow
    \node (processor_header) [layerheader] at (0, 0) {dataProcessor.m};
    \node (proc_event) [startstop, below=of processor_header, align=center] {Chirp processed};
    \node (add_buffer) [process, below=of proc_event] {Add to ping-pong buffer};
    \node (buffer_full) [decision, below=of add_buffer] {Buffer full?};
    \node (start_update) [process, below=of buffer_full] {Start cube update};
    \node (end_func) [startstop, below=of start_update] {End function};

    % radarDataCube.m flow
    \node (cube_header) [layerheader] at (9.5, 0) {radarDataCube.m};
    \node (cube_start) [startstop, below = of cube_header] {Update started};
    \node (keep_raw) [decision, below = of cube_start] {Keep RAW?};
    \node (use_spread) [decision, right=of keep_raw, align=center, xshift=+0.7cm] {Use spread\\pattern?};
    \node (direct_update) [process, below=of use_spread, align=center] {Update raw cube\\decay?};
    \node (create_subcube) [process, below=of direct_update] {Create subcube};
		\node (aggregate) [process, below =of create_subcube, align=center] {Aggregate updates};
		\node (aggregate2) [process, below =of aggregate, align=center] {Update raw cube\\decay?};
    \node (keep_cfar) [decision, below=2cm of keep_raw] {Keep CFAR?};
    \node (update_cfar) [process, below=of keep_cfar, align=center] {Update CFAR cube\\ decay?};
    \node (cube_return) [startstop, below= of update_cfar] {Return};

    % Connections
    \draw [arrow] (proc_event) -- (add_buffer);
    \draw [arrow] (add_buffer) -- (buffer_full);
    \draw [arrow] (buffer_full.south) -- node[right] {Yes} (start_update.north);
    \draw [arrow] (start_update.south) -- (end_func.north);
    \draw [arrow] (buffer_full.west) -- ++(-1.5,0) node[left] {No} |- (end_func.west);
    %
    \draw [arrow] (cube_header) -- (cube_start);
    \draw [arrow] (cube_start) -- (keep_raw);
    \draw [arrow] (keep_raw.east) -- node[above] {Yes} (use_spread.west);
    \draw [arrow] (keep_raw.south) -- node[right] {No} (keep_cfar.north);
    \draw [arrow] (use_spread.south) -- node[right] {No} (direct_update.north);
    \draw [arrow] (direct_update.west) -- ++(0,0) -| (keep_cfar.north);
    \draw [arrow] (use_spread.east) -- ++(1,0) node[above] {Yes} |- (create_subcube.east);
    \draw [arrow] (create_subcube) -- (aggregate);
    \draw [arrow] (aggregate) -- (aggregate2);
    \draw [arrow] (aggregate2.west) -| ++(-0.5,12.396 ) -| (keep_cfar.north);
    %
    \draw [arrow] (keep_cfar.west) -- ++(-1,0) node[above] {No} |- (cube_return.west);
    \draw [arrow] (keep_cfar.south) -- node[right] {Yes} (update_cfar.north);
    \draw [arrow] (update_cfar.south) -- (cube_return.north);
    %
  \end{tikzpicture}
  \caption{Processing flow - Cube update}
  \label{fig:cube_flow}
\end{figure}

Update routine for cubes containing CFAR or raw data, are quite simmilar, in the case if spread pattern is disabled.
New data are just added to the cube to their respective positions where they replace old ones.
In case cube is set to decay (\texttt{Cube decay} option is set to decay.) whole cube is multiplied by a decay factor that is derived from platforms movement speed.
The slower the platform moves the slower the data decay.
Using this option leads to an output more visually resembling radar  traditional analogue radar systems where most recent data were brighter than the older ones.
However user needs to keep in mind that color changes doesn't mean a change in RCS at that position.
In addition this operation is rather computationally expensive and is the primary reason updates to the cube must be buffered.

Even on smaller cubes of around 256~MB this operations takes in worse case some 50~ms to complete on a laptop i7-10210U CPU.
If change of value would be undesirable behaviour decay can be turned off in the settings in favour of hard reset of the cube based on trigger on specified yaw position.
Rest of the processing is then fast enough to keep up with the data stream without any buffering.

Enabling spread pattern leads to degradation of quality of the data in exchange for better visualization quality -- especially in range-azimuth visualization style.
Instead of adding new data just to one position in the cube the range-Doppler map is spread over a larger area with aid of a 2D matrix, made up of a 2D Gaussian function.
As the data in series are usually close to each other in terms of position update process can be made more efficiently.
Instead of directly adding these contributions to the full cube much smaller cube is created.
That cubes covers only the area that will be updated with the new data and is later added to the full cube in one go.
This enables significant speedup as smaller memory size enables better cacheing.
Still in case of a more performant radar system this method would be unncessary not to mention has very little basis in radar data processing theory.

Due to lacking performance of MATLAB on author's machine some parts of the cube update routine were implemented in C++ with the aid of MATLAB's MEX interface.
This enabled the use of AVX2 x86 instruction set extension to speed up floating point operations.
Chiefly decaying of the cube exhibited roughly two fold performance increase thanks to SIMD instructions.


\section{Visualization}

After cube update finishes program returns to the main thread and the data are visualized.
Only way user can see the data is via visualization.
Text output or other methods are not available.
However the application offers a number of different visualization styles to suit the user's requirements.

\begin{enumerate}
	\item Range-Azimuth: Polar plot with range on the radius and azimuth on the angle.
	\item Range-Doppler: Classical xy plot with range on x axis and Doppler on y axis, if speed is not calculated the y axis is replaced with RCS value.
	\item Target-3D: CFAR data are displayed in 3D cartesian space
\end{enumerate}

\subsection{Range-Azimuth}

This visualization style is used to display the data in polar plot for fixed pitch angle that is chosen by an text box.
The demonstration of Range-Azimuth map can be seen on figure \ref{fig:main_window}, which captures testing with 122~GHz header with rather large bandwidth of 3~GHz giving only some 5 meters of range.
On the picture only raw data are displayed however this visualization style is able to also display CFAR data or overlay both of them.

Instead of calculating projection into horizontal plane the data are displayed in a conical projection.
That is, no additional calculations are made and the cone we get by fixing the pitch angle is simply stretched to a circle.
To aid with orientation in a plot simple line markers are added to provide range and angle reference points.

This visualization style might be especially usefull when paired with 24~GHz header.
Due to it's rather wide radiation pattern the radar is able to detect objects in quite a large area.
This can be even more extended if the spread pattern is enabled where more pitch angles will influcence the data.
Thus for a realization of classical surveillance radar this method of visualization might be most versatile.

\subsection{Range-Doppler}

Picking this visualization style from the preferences menu will display the data in a classical x-y plot for a fixed yaw and pitch angle.
Just as with Range-Azimuth map both angles are configurable via the textboxes at the bottom of the screen.
In cases when speed calculation is disabled the y axis is replaced with RCS value.

Main purpose of this visualization style is to provide verification method for the radar data processing and setting.
As the devkit doesn't report much of a useful errors and its technical documentation is sometimes incorrect (e.g. in allowed bandwidth values) it is useful to have a way to verify that the radar is working correctly.

\begin{figure}[h!]
  \centering
  \begin{subfigure}[b]{0.45\textwidth}
    \centering
    \includegraphics[width=\textwidth]{../img/vis_range_dop.jpg}
    \caption{Range-Doppler map}
  \end{subfigure}
  \hspace{0.05\textwidth}
  \begin{subfigure}[b]{0.45\textwidth}
    \centering
    \includegraphics[width=\textwidth]{../img/vis_range_rcs.jpg}
    \caption{Range-RCS }
  \end{subfigure}
	\caption{Range-Doppler and Range-RCS maps}
  \label{fig:rd_rr_map}
\end{figure}

On figure \ref{fig:rd_rr_map} we can see two different visualization styles both displaying the same static scene.
As previously stated given rather poor sampling rate speed calculation is not very useful and thus no complex testing has been done of it.

\newpage
\subsection{Target-3D}

\begin{figure}[h!]
	\centering
	\includegraphics[width=0.9\textwidth]{../img/vis_3d.jpg}
	\caption[3D Space visualization method]{3D Space visualization method}
	\label{fig:vis3d}
\end{figure}

This visualization style is used to display CFAR data in 3D cartesian space (Figure \ref{fig:vis3d}).
Visualization method is rather simple with just positions being recalculated from the range, azimuth and pitch angles to x, y and z coordinates using trigonometric functions.
In case decay is enabled then small threshold is used to remove points whose values was sufficiently regraded.
To aid with orientation within the plot curret heading of the platform is displayed as a red line.

If environment is too cluttered and CFAR generates too many points the user can enable basic clustering with MATLAB's built in DBSCAN function \cite{matlab_dbscan}.
Gerneral idea of DBSCAN is that for a given point in the dataset distances to other points are calculated and compared with user defined threshold $\varepsilon$, in case sufficient number $N$ of points is found within the threshold the point is marked as part of an cluster \cite{Kellner2012}.
In MATLAB's in algorithm distance threshold and minimal number of points are both configurable variables with other input being just the points list \cite{matlab_dbscan}.
As original data are in polar coordinates system problem arises with calculating distances given that in such system distance between two points of given fixed yaw and pitch varies widely with range.
Not to mention with increasing distance the density of data points decreases.
Aside from that we also have significantly more points closer to the radar as space is much more densely scanned there compared to the far end of the range.

These problems can be overcome using many different methods like using adaptive thresholds in relation to radius \cite{Kellner2012} or relying on more clever axis systems then just polar or cartesian \cite{Sun2024}.
However as in this thesis as DBSCAN is more of an illustration of possible postprocessing no such complex methods were implemented.
Both $\varepsilon$ and $N$ parameters are left to the user to configure with \texttt{DBSCAN epsilon} and \texttt{DBSCAN min count}.
As for the distance metric points are at firstly converted to cartesian coordinates then distance is calculated using standard euclidean formula.
This distance is then divided by averaging radiuses of points.
Still it needs to be said that, while dividing by the mean of distances is sometimes used when working with spherical data \cite{Fisher1993}, author is not aware of any literature that would suggest use in DBSCAN.
Especially on longer distance this methods will lead to significant errors.

\newpage
\pagestyle{plain}

\include{conclusion}

\include{bibliography}

\listoffigures

\listoftables

\include{appendix}

\clearpage
\openright
\end{document}
